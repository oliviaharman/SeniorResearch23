{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all of the files to upload to the server - will have to do this for snake dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to split the data to get it ready to train the model\n",
    "##### Remember to open the notebook within the conda environment created!!!!!! cd to environment and \"jupyter notebook\" to open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_DATA_DIR = \"C:\\TutorialBuild\\BrainTumor\"\n",
    "num_of_images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir(SEED_DATA_DIR):\n",
    "    num_of_images[dir] = len(os.listdir(os.path.join(SEED_DATA_DIR, dir )))\n",
    "\n",
    "print (num_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to create 3 folders: 70% train data, 15% validation data and 15% test data\n",
    "\n",
    "TRAIN_DIR =  \"C:\\TutorialBuild\\BrainTumor\\\\train\"\n",
    "VALIDATE_DIR =  \"C:\\TutorialBuild\\BrainTumor\\\\validate\"\n",
    "TEST_DIR =  \"C:\\TutorialBuild\\BrainTumor\\\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train folder :\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    os.mkdir(TRAIN_DIR)\n",
    "\n",
    "    for dir in os.listdir(SEED_DATA_DIR):\n",
    "        os.makedirs(TRAIN_DIR + \"/\" + dir)\n",
    "        print (TRAIN_DIR + \"/\" + dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(SEED_DATA_DIR,dir)) , size= (math.floor(70/100* num_of_images[dir] )-5) , replace=False ):\n",
    "            O = os.path.join(SEED_DATA_DIR, dir , img)\n",
    "            print(O)\n",
    "            D = os.path.join(TRAIN_DIR, dir)\n",
    "            print(D)\n",
    "            shutil.copy(O,D)\n",
    "            os.remove(O)\n",
    "else:\n",
    "    print(\"Train Folder Exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test folder:\n",
    "if not os.path.exists(TEST_DIR):\n",
    "    os.mkdir(TEST_DIR)\n",
    "\n",
    "    for dir in os.listdir(SEED_DATA_DIR):\n",
    "        os.makedirs(TEST_DIR + \"/\" + dir)\n",
    "        print (TEST_DIR + \"/\" + dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(SEED_DATA_DIR,dir)) , size= (math.floor(15/100* num_of_images[dir] )-5) , replace=False ):\n",
    "            O = os.path.join(SEED_DATA_DIR, dir , img)\n",
    "            print(O)\n",
    "            D = os.path.join(TEST_DIR, dir)\n",
    "            print(D)\n",
    "            shutil.copy(O,D)\n",
    "            os.remove(O)\n",
    "else:\n",
    "    print(\"Test Folder Exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the validate folder:\n",
    "if not os.path.exists(VALIDATE_DIR):\n",
    "    os.mkdir(VALIDATE_DIR)\n",
    "\n",
    "    for dir in os.listdir(SEED_DATA_DIR):\n",
    "        os.makedirs(VALIDATE_DIR + \"/\" + dir)\n",
    "        print (VALIDATE_DIR + \"/\" + dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(SEED_DATA_DIR,dir)) , size= (math.floor(15/100* num_of_images[dir] )-5) , replace=False ):\n",
    "            O = os.path.join(SEED_DATA_DIR, dir , img)\n",
    "            print(O)\n",
    "            D = os.path.join(VALIDATE_DIR, dir)\n",
    "            print(D)\n",
    "            shutil.copy(O,D)\n",
    "            os.remove(O)\n",
    "else:\n",
    "    print(\"Validate Folder Exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here  we are building the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cla\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, MaxPool2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR =  \"C:\\TutorialBuild\\BrainTumor\\\\train\"\n",
    "VALIDATE_DIR =  \"C:\\TutorialBuild\\BrainTumor\\\\validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape = (224,224,3)    ))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),  activation='relu' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),  activation='relu' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3),  activation='relu' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "#final layer:\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    zoom_range=0.2 , shear_range=0.2, rescale=1. / 255 , horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = image.ImageDataGenerator( rescale= 1. / 255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(directory=TRAIN_DIR , target_size=(224,224) , batch_size=32 , class_mode='binary')\n",
    "val_data = val_datagen.flow_from_directory(directory=VALIDATE_DIR, target_size=(224,224), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model check point for the performence of the model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets stop the training if the accuracy is good\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta=0.01 , patience=5 , verbose=1 , mode='auto')\n",
    "mc = ModelCheckpoint(filepath='C:\\TutorialBuild\\BrainTumor\\MyBestModel.h5', monitor='val_accuracy' ,  verbose=1 , mode='auto' , save_best_only=True)\n",
    "\n",
    "\n",
    "call_back = [es, mc]\n",
    "\n",
    "hist = model.fit(x=train_data, epochs=30 , verbose=1, validation_data=val_data, callbacks=call_back)\n",
    "\n",
    "h = hist.history\n",
    "print('Keys : ', h.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot the accuracy and the loss\n",
    "#===================================\n",
    "\n",
    "\n",
    "#accuracy \n",
    "plt.plot(h['accuracy'])\n",
    "plt.plot(h['val_accuracy'], c='red')\n",
    "plt.title('Accuracy vs. Val Accuracy')\n",
    "plt.show()\n",
    "\n",
    "#loss\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['val_loss'], c='red')\n",
    "plt.title('loss vs. Val loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we want to check the accuracy of the model with the test data. Then we will run predictions on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locale import normalize\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = \"C:\\TutorialBuild\\BrainTumor\\\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = image.ImageDataGenerator( rescale= 1. / 255)\n",
    "test_data = test_datagen.flow_from_directory(directory=TEST_DIR , target_size=(224,224) , batch_size=32 , class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets print the classes :\n",
    "\n",
    "print(\"test_data.class_indices: \", test_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model :\n",
    "\n",
    "model = load_model('C:\\TutorialBuild\\BrainTumor\\MyBestModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.summary() )\n",
    "\n",
    "acc = model.evaluate(x=test_data)[1]\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from the test folder \n",
    "imagePath = \"C:\\TutorialBuild\\BrainTumor\\test\\Healthey\\Not Cancer  (1523).jpg\"\n",
    "#imagePath = \"C:/Python-cannot-upload-to-GitHub/BrainTumor/test/Brain Tumor/Cancer (17).jpg\"\n",
    "\n",
    "img = image.load_img(imagePath,target_size=(224,224))\n",
    "i = image.img_to_array(img) # convert to array\n",
    "i = i / 255 # -> normalize to our model\n",
    "print(i.shape)\n",
    "\n",
    "input_arr = np.array([i]) # add another dimention \n",
    "print(input_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the prediction\n",
    "predictions = model.predict(input_arr)[0][0]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is binary if the result is close to 0 it is Tumor , and if it close to 1 it is healthy\n",
    "result = round(predictions)\n",
    "if result == 0 :\n",
    "    text = 'Has a brain tumor'\n",
    "else :\n",
    "    text = \"Brain healthy\"\n",
    "\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResult = cv2.imread(imagePath)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(imgResult, text, (0,20), font, 0.8 , (255,0,0),2 )\n",
    "cv2.imshow('img', imgResult)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"C:\\TutorialBuild\\BrainTumor\\predictImage.jpg\",imgResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
